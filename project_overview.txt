RAG Knowledge Base â€“ Project Overview

This project is a Retrieval-Augmented Generation (RAG) knowledge base system built using FastAPI, PostgreSQL with pgvector, and OpenAI models.

The goal of the project is to demonstrate how unstructured text can be ingested, embedded, stored, and queried using semantic search, and then used to generate grounded answers via a large language model.

Core Components:

1. API Layer
The API is built using FastAPI and exposes endpoints for ingestion, search, and chat. Swagger UI is enabled for easy testing and exploration.

2. Ingestion Pipeline
The ingestion pipeline performs the following steps:
- Accepts raw text input or uploaded text files
- Splits the text into overlapping chunks
- Generates embeddings for each chunk using OpenAI embedding models
- Stores the chunks, metadata, and embeddings in PostgreSQL using pgvector

3. Vector Store
PostgreSQL with the pgvector extension is used as the vector database. Each text chunk is stored along with a vector embedding, allowing efficient similarity search using vector distance operators.

4. Retrieval
When a user submits a query:
- The query is embedded using the same OpenAI embedding model
- A similarity search is performed using pgvector
- The top-K most relevant chunks are retrieved based on vector distance

5. Chat (RAG)
The chat endpoint implements Retrieval-Augmented Generation:
- Retrieved chunks are injected as context into the prompt
- The language model is instructed to answer strictly using the provided context
- Citations are included to show which chunks were used to generate the answer
- If the context is insufficient, the assistant responds that it does not know

6. Safety and Hallucination Control
The system prompt enforces strict grounding rules:
- The model must only answer using retrieved context
- The model must cite sources when using them
- The model must avoid hallucination and ask clarifying questions if needed

7. Chatbot UI
A minimal web-based chatbot UI is served directly by FastAPI. It allows users to:
- Ask questions
- View answers generated by the RAG pipeline
- See citations for transparency

Use Cases:
- Internal documentation assistant
- Knowledge base search
- Project documentation Q&A
- Developer onboarding assistant

This project is designed to be modular, production-oriented, and interview-ready, demonstrating practical RAG system design rather than a toy example.